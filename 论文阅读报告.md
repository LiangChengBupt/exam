# 阅读报告

该论文题为《Towards Building Multilingual Language Model for Medicine》，，旨在开发一个开源的、专门用于医学领域的多语言模型。论文的主要贡献包括：

1. **多语言医学语料库（MMedC）**：作者第一次构建了一个大规模的多语言医学语料库，包含约255亿个词元，涵盖六种主要语言（英语、中文、日语、法语、俄语和西班牙语）。该语料库用于现有通用大型语言模型（LLM）的自回归训练。增强了在非英语语言的医学查询上的表现
2. **多语言医学基准（MMedBench）**：论文介绍了一个新的多语言医学问答基准，带有推理部分，旨在评估LLM在多种语言下对医学查询的表现。
3. **评估与结果**：论文评估了多种流行的开源LLM在新基准上的表现。最终的模型MMedLM 2，仅有7B参数，在MMedBench上的表现优于所有其他开源模型，甚至可与GPT-4媲美。
4. **MMedLM**：这是第一个在多语言语料库上训练的医学大语言模型，

## 优点：
- **全面的多语言语料库**：创建MMedC这一大规模且多样化的医学语料库是一个显著的优点，使LLM能够在多个语言的医学领域内进行良好适应。
- **基准开发**：MMedBench提供了一个有价值的工具，用于评估LLM在医学领域的表现，考虑到多项选择题的准确性和推理生成能力。
- **性能提升**：开发的模型MMedLM 2显示出相较于现有模型的显著改进，突显了专门训练语料库的有效性。

## 缺点：
- **模型参数只有7B**：限制于模型的参数量，可能会出现7B模型都存在的幻觉问题。如果能够增加参数量，效果应该会更好。
- **数据集构建**：在数据集构建的过程中，设置不同语言的关键词匹配阈值，通过测试多语言数据集CulturalX确定医学内容。生成的数据集范围和质量首先于关键词的选择。
- **其他领域的泛化性**：语料库和基准的专门性质可能限制了研究成果在非医学领域的泛化性。

### 语言范围有限

目前语料库仅涵盖六种语言：

在[《Apollo: An Lightweight Multilingual Medical LLM towards Democratizing Medical AI to 6B People》](https://arxiv.org/pdf/2403.03640)中，对MMedLM2-7B进行了评测，可以看到在**阿拉伯语和印地语**上的表现较差，因为预料库中不包含这两种语言，所以可以理解。同时在训练过的英语，中文，法语和西班牙上表现亮眼（同规模7B模型）。

![image-20240531022824684](../../%E5%9B%BE%E7%89%87/Typora/image-20240531022824684.png)

### 数据集

在[《Aloe: A Family of Fine-tuned Open Healthcare LLMs》](https://arxiv.org/pdf/2405.01886)中，对MMedLM2-7B在细分疾病上的能力进行了评测：

![image-20240531024348133](../../%E5%9B%BE%E7%89%87/Typora/image-20240531024348133.png)

从表中可以看到，MMedLM2在各个数据集上的表现都非常不错，没有出现在某一个数据集上的效果异常（高/低），说明筛选的数据质量不错。

![image-20240531025305804](../../%E5%9B%BE%E7%89%87/Typora/image-20240531025305804.png)

在各个细分医学领域同样表现稳定（低于SOTA10%左右），这篇文章使用的moe没有可比性。



![image-20240531025709870](../../%E5%9B%BE%E7%89%87/Typora/image-20240531025709870.png)

1. **Crows pairs (English) ↓**：这个指标衡量模型在处理英语文本时的偏见水平，数值越低表示偏见越少。
2. **Hendrycks ethics ↑**：这个指标评估模型在伦理道德方面的表现，数值越高表示表现越好。
3. **Sycophancy ↓**：这个指标评估模型是否会迎合用户，即使在用户提供错误信息的情况下。数值越低表示迎合行为越少。
4. **Truthfulqa (mc2) ↑**：这个指标评估模型在回答多项选择问题时的真实性，数值越高表示真实性越高。
5. **Toxigen Generation ↓**：这个指标评估模型生成有毒或有害内容的程度，数值越低表示生成有毒内容的可能性越小。

- **MMedLM2**：在Crows pairs测试中得分为65.53（偏见较低），Hendrycks ethics得分为66.05（伦理道德表现一般），Sycophancy得分为70.73（迎合行为较少），Truthfulqa得分为49.62（真实性一般），Toxigen Generation得分为9.31（生成有毒内容的可能性中等）。

## 可能加强的方向

### 使用更大的模型

### MMedLM 2只是在语料库上进行了训练

后续可以使用**RAG**，**向量数据库**，**MoE**，**多Agent系统**，**工具调用**，**CoT**这些技术来增强能力。

现在的研究与这些技术正交，不需要去竞争刷点。